{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parksangeeon/AI/blob/main/%5BAI2025_Assignment%5D_CIFAR10_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4wZyk6PTCgK"
      },
      "source": [
        "2# CIFAR10 Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ_41-SSu5_8"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mMmpe3nHuzlE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_beAzBMXWOW"
      },
      "source": [
        "### Data Preparation\n",
        "Use CIFAR10 handwriting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v-EHyWvzXWOX"
      },
      "outputs": [],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_7rOwoDXWOX"
      },
      "source": [
        "Prepare data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7iDlKPvfXWOX"
      },
      "outputs": [],
      "source": [
        "# train / test split\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# minmax normalization\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RNqanoWXWOY"
      },
      "source": [
        "# Compile and Train neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQuBo9QmXWOY"
      },
      "source": [
        "## CNN Modeling\n",
        "Create a convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Q5P2KVJZhJ"
      },
      "source": [
        "### Goal\n",
        "\n",
        "Improve the provided basic CNN model and achieve CIFAR-10 **test accuracy ≥ 75%**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24LRh6qOg6Bo"
      },
      "source": [
        "Modify the network architecture!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3V_IqXaX-gYS"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    # Convolutional layer. Learn 64 filters using a 3x3 kernel\n",
        "    tf.keras.layers.Conv2D(\n",
        "        64, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)\n",
        "    ),\n",
        "    # Max-pooling layer, using 2x2 pool size\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Convolutional layer. Learn 128 filters using a 3x3 kernel\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    # Max-pooling layer, using 2x2 pool size\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Convolutional layer. Learn 246 filters using a 3x3 kernel\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
        "    # Max-pooling layer, using 2x2 pool size\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Flatten units\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Add a hidden layer with dropout\n",
        "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Add a hidden layer with dropout\n",
        "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Add an output layer with output units for all 10 digits\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Train neural network"
      ],
      "metadata": {
        "id": "hBdmMsv7_-v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "history = model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6LcMeR_9vL",
        "outputId": "15cf1586-da17-4239-f9be-ffde390749df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2502 - loss: 1.9639\n",
            "Epoch 2/10\n",
            "\u001b[1m1294/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4231 - loss: 1.5703"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0G4azd0XWOY"
      },
      "source": [
        "## Evaluate neural network performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA8GRgLTXWOZ"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHwJZ9PdXWOZ"
      },
      "outputs": [],
      "source": [
        "prob = model.predict(x_test[0:40], verbose=0)\n",
        "pred = tf.argmax(prob, axis=1)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 18))\n",
        "for i in range(40):\n",
        "    subplot = fig.add_subplot(8, 5, i + 1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    string = r'$\\hat{y}$'\n",
        "    subplot.set_title(f'$y$:{tf.argmax(y_test[i])}, {string}:{pred[i].numpy()}')\n",
        "    subplot.imshow(tf.squeeze(x_test[i]))\n",
        "plt.show()\n",
        "true_label = tf.argmax(y_test[i]).numpy()\n",
        "pred_label = pred[i].numpy()\n",
        "plt.title(f\"GT: {true_label}, Pred: {pred_label}\")\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "XVOGAnq4tJ7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}